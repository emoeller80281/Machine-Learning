{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787f3160",
   "metadata": {},
   "source": [
    "# Word Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d1a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f00cd11d950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0440f",
   "metadata": {},
   "source": [
    "We create random tensors for the vocabulary, where each word has an embedding vector associated with it. We create an index where the word at index $i$ has it's embedding stored in the $i^{th}$ row of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4bb839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5) # 2 words in vocab, 5 dimensional embeddings. Starts with random weights between -1 and 1\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long) # Converts the value of \"hello\" (0) to a tensor\n",
    "hello_embed = embeds(lookup_tensor) # Lookup the tensor for \"hello\" at position 0\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b732c",
   "metadata": {},
   "source": [
    "Let's train a simple neural network called an **N-Gram Language Model**, which tries to predict the word at position $i$ given the preceeding 2 words. It will use the trainable vector embeddings of the input words as the input, and try to predict which word comes next. By representing the numbers as a long series of embedded numbers, the neural network can modify the weights to learn to associate different words together. \n",
    "\n",
    "First, let's set a **context size** of 2, meaning that the neural network will look at the previous two words when making it's prediction. We will set an **embedding dimension** of 10, which will give five *latent semantic attributes** to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8467fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'forty', 'winters', 'shall', 'besiege']\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "print(test_sentence[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf128f7",
   "metadata": {},
   "source": [
    "We will split the test sentence into a list of tuples, where each tuple contains the word that should be predicted and a list of the two words preceding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47140ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['forty', 'When'], 'winters'), (['winters', 'forty'], 'shall'), (['shall', 'winters'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "print(ngrams[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bdce9",
   "metadata": {},
   "source": [
    "Next, we make a set of the unique words in the passage as our vocabulary and create a word to index mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfe7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab has 97 unique words\n"
     ]
    }
   ],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "print(f\"Vocab has {len(vocab)} unique words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72508df4",
   "metadata": {},
   "source": [
    "We can now define the structure of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc1080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)       # 97 unique words * 10 embeddings for each word\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)     # Input = 20 (context of 2 words * embedding size of 10 -> 128 neurons\n",
    "        self.linear2 = nn.Linear(128, vocab_size)                       # Input = 128 neurons -> 97 unique words\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(1, -1)                    # Squeezes the 10-length embeddings for the two words into a single 20-length tensor\n",
    "        out = F.relu(self.linear1(embeds))                              # RelU activation function after the first neural network\n",
    "        out = self.linear2(out)                                         # Runs the output of the first layer through the second layer\n",
    "        log_probs = F.log_softmax(out, dim=1)                           # Returns the log probability for each word in the vocab using log softmax\n",
    "        return log_probs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a5df0",
   "metadata": {},
   "source": [
    "We will use the **negative log likelihood loss** function, which is useful for training classification problems. We will use the **stochastic gradient descent** optimizer for calculating parameter gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b13a8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739c59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: 97 unique words * 10 embedding dimension\n",
      "Linear1 layer: 20 inputs -> 128 outputs\n",
      "Linear2 layer: 128 inputs -> 97 outputs (1 for each word)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding layer: {model.embeddings.num_embeddings} unique words * {model.embeddings.embedding_dim} embedding dimension\")\n",
    "print(f\"Linear1 layer: {model.linear1.in_features} inputs -> {model.linear1.out_features} outputs\")\n",
    "print(f\"Linear2 layer: {model.linear2.in_features} inputs -> {model.linear2.out_features} outputs (1 for each word)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f6028",
   "metadata": {},
   "source": [
    "Now we can define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "523af072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_idxs = [tensor([23, 72])]\n",
      "Losses: [273.81, 271.05, 268.28, 265.51, 262.75]...[157.99, 155.78, 153.59, 151.42, 149.27]\n",
      "Final word embedding for 'beauty' \n",
      "\ttensor([-1.0367, -0.6847,  0.3079,  1.1811, -0.0095, -0.2741,  0.4733, -0.1618,\n",
      "         0.3827,  2.3051], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "first_context = []\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "        \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e., turn the words \n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        if len(first_context) == 0:\n",
    "            first_context.append(context_idxs[:3])\n",
    "        \n",
    "        # Step 2. Recall that torch accumulates gradients. Before passing in a new instance,\n",
    "        # you need to zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Step 3. Run the forward pass, getting the log probabilities over the next words\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        # Step 4. Compute your loss function (Again, Torch wants the target word wrapped\n",
    "        # in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        \n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get the Python number from a 1-element tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(f\"context_idxs = {first_context}\")\n",
    "print(f\"Losses: {[round(i, 2) for i in losses[:5]]}...{[round(i, 2) for i in losses[-5:]]}\")\n",
    "\n",
    "# To get teh embedding of a particular word, e.g. \"beauty\"\n",
    "word = \"beauty\"\n",
    "print(f\"Final word embedding for '{word}' \\n\\t{model.embeddings.weight[word_to_ix[word]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655daaab",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words\n",
    "\n",
    "Frequently used in NLP deep learning, this model tries to predict words given the context of a few words before and after the target word.\n",
    "\n",
    "Given a target word $w_{i}$ and an $N$ context window on each side, $w_{i-1},...,w_{i-N}$ and $w_{i+1},...,w_{i+n}$, referring to all context words collectively as $C$, CBOW tries to minimize:\n",
    "\n",
    "$$-\\text{log}p(w_{i}|C)=-\\text{log}\\text{Softmax}\\left(A(\\sum_{w \\in C}q_{w}+b)\\right)$$\n",
    "\n",
    "Where $q_{w}$ is the embedding for word $w$.\n",
    "\n",
    "We will use a **context size** of 2, to look at two words to the left and two to the right of the target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3798dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['are', 'We', 'to', 'study'], 'about'), (['about', 'are', 'study', 'the'], 'to'), (['to', 'about', 'the', 'idea'], 'study')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "\n",
    "# Iterate through each target word, from the 3rd word to the N-3rd word in the sequence\n",
    "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
    "    context = (\n",
    "        [raw_text[i - j - 1] for j in range(CONTEXT_SIZE)] +    # Get the words behind the target\n",
    "        [raw_text[i + j + 1] for j in range(CONTEXT_SIZE)]      # Get the words in front of the target\n",
    "    )\n",
    "    target = raw_text[i]                                        # Get the target\n",
    "    data.append((context, target))\n",
    "\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49289cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'We', 'to', 'study']\n"
     ]
    }
   ],
   "source": [
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)           # Vocab size of\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim * 2, 128)     # Input = 40 (context of 2 words * embedding size of 10 * 2 for words before and after -> 128 neurons\n",
    "        self.linear2 = nn.Linear(128, vocab_size)                           # Input = 128 neurons -> 97 unique words\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view(1, -1)                    # Squeezes the 10-length embeddings for the two words into a single 20-length tensor\n",
    "        out = F.relu(self.linear1(embeds))                              # RelU activation function after the first neural network\n",
    "        out = self.linear2(out)                                         # Runs the output of the first layer through the second layer\n",
    "        log_probs = F.log_softmax(out, dim=1)                           # Returns the log probability for each word in the vocab using log softmax\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d03d4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ed69925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: 49 unique words * 10 embedding dimension\n",
      "Linear1 layer: 40 inputs -> 128 outputs\n",
      "Linear2 layer: 128 inputs -> 49 outputs (1 for each word)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding layer: {model.embeddings.num_embeddings} unique words * {model.embeddings.embedding_dim} embedding dimension\")\n",
    "print(f\"Linear1 layer: {model.linear1.in_features} inputs -> {model.linear1.out_features} outputs\")\n",
    "print(f\"Linear2 layer: {model.linear2.in_features} inputs -> {model.linear2.out_features} outputs (1 for each word)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23828322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_idxs = [tensor([47, 27, 43])]\n",
      "Losses: [36.06, 35.46, 34.86, 34.28, 33.7]...[17.75, 17.5, 17.26, 17.02, 16.79]\n"
     ]
    }
   ],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    \"\"\"Converts the input to a tensor with their corresponding indices in `word_to_ix`\"\"\"\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "losses = []\n",
    "first_context = []\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for context, target in data:\n",
    "        \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e., turn the words \n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        if len(first_context) == 0:\n",
    "            first_context.append(context_idxs[:3])\n",
    "        \n",
    "        # Step 2. Recall that torch accumulates gradients. Before passing in a new instance,\n",
    "        # you need to zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Step 3. Run the forward pass, getting the log probabilities over the next words\n",
    "        log_probs = model(context_idxs)\n",
    "        \n",
    "        # Step 4. Compute your loss function (Again, Torch wants the target word wrapped\n",
    "        # in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        \n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get the Python number from a 1-element tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "print(f\"context_idxs = {first_context}\")\n",
    "print(f\"Losses: {[round(i, 2) for i in losses[:5]]}...{[round(i, 2) for i in losses[-5:]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3519299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final word embeddings for:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dim1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim4",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim5",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim6",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim7",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim8",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim9",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "Dim10",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "4e995536-abe4-4649-bcf3-26d7d796bdaa",
       "rows": [
        [
         "computational",
         "-0.6675423",
         "0.33450788",
         "-1.2473751",
         "-0.56265986",
         "-1.7713785",
         "-0.75433",
         "0.63513374",
         "-0.24155313",
         "0.43832427",
         "1.810085"
        ],
        [
         "processes",
         "-0.3140255",
         "-0.45943955",
         "0.58965",
         "1.7200785",
         "-0.5688933",
         "-0.85016024",
         "0.46090508",
         "-2.7003133",
         "-0.9368562",
         "-0.90749"
        ],
        [
         "spells.",
         "-0.17085144",
         "1.5825098",
         "-1.1865569",
         "1.3033309",
         "-0.5109694",
         "2.3349655",
         "-1.9356045",
         "1.2258577",
         "0.7734847",
         "0.037680883"
        ],
        [
         "about",
         "-1.2073954",
         "0.34138945",
         "0.7021236",
         "1.0287969",
         "-0.75189096",
         "0.03164322",
         "-1.5734223",
         "-1.5395769",
         "0.9633991",
         "-0.5955372"
        ],
        [
         "The",
         "1.9931703",
         "-1.1234821",
         "0.6948609",
         "-0.5772102",
         "-0.56987727",
         "0.53646094",
         "0.929991",
         "0.48841602",
         "-0.2833663",
         "0.33653954"
        ],
        [
         "other",
         "0.3728923",
         "-0.3921719",
         "-0.0429598",
         "0.914083",
         "0.14985283",
         "-1.8745306",
         "-0.28394252",
         "0.23976958",
         "0.6779131",
         "1.2535366"
        ],
        [
         "processes.",
         "0.1696967",
         "0.29853034",
         "0.46882188",
         "0.6258501",
         "0.580149",
         "0.0878164",
         "-1.1162876",
         "0.6201692",
         "1.0679764",
         "-1.2257997"
        ],
        [
         "rules",
         "-0.8709459",
         "-0.9309829",
         "-1.6575677",
         "-0.18802677",
         "-0.20470372",
         "-0.15920642",
         "0.2389137",
         "0.16836226",
         "0.75072426",
         "-0.64840513"
        ],
        [
         "evolution",
         "-0.30710182",
         "-0.053045116",
         "1.2619289",
         "-1.1994925",
         "0.87961197",
         "-1.0453322",
         "-0.24968705",
         "0.67650986",
         "-1.3443244",
         "-0.34103072"
        ],
        [
         "Computational",
         "2.054966",
         "0.9275702",
         "-0.8672039",
         "-1.5017365",
         "-0.68750006",
         "1.1942669",
         "0.036527187",
         "-0.6481184",
         "-0.6347958",
         "0.6357308"
        ],
        [
         "they",
         "0.67601097",
         "-0.41585442",
         "0.49885967",
         "-0.44585273",
         "-0.9677897",
         "-0.5374028",
         "0.73202884",
         "-1.168036",
         "-1.8594437",
         "-2.0670574"
        ],
        [
         "evolve,",
         "-0.10210613",
         "-0.185345",
         "-1.1552886",
         "-1.4334149",
         "-0.41932333",
         "0.1230547",
         "0.06130316",
         "0.2592104",
         "0.43425673",
         "-1.3940749"
        ],
        [
         "things",
         "-0.40025994",
         "0.418056",
         "1.4882454",
         "0.6877217",
         "1.0882366",
         "-0.74350417",
         "1.4925439",
         "0.38309556",
         "0.30070478",
         "0.02863637"
        ],
        [
         "we",
         "0.24451616",
         "1.1929957",
         "-0.15231925",
         "-0.6088604",
         "0.121004805",
         "1.8678572",
         "-0.2928292",
         "-0.97452986",
         "0.89145046",
         "-0.2913005"
        ],
        [
         "program.",
         "0.60028744",
         "-0.6592605",
         "-0.4452823",
         "-2.6790326",
         "-0.45081496",
         "-0.5465754",
         "-0.8217887",
         "0.058136497",
         "-1.092267",
         "-1.1659095"
        ],
        [
         "People",
         "0.98367137",
         "0.9157287",
         "-1.7710345",
         "-1.0624145",
         "0.2736304",
         "0.052560195",
         "0.76635027",
         "1.0360818",
         "0.20533608",
         "-0.25703835"
        ],
        [
         "computer",
         "0.15238094",
         "1.5812998",
         "-0.86879355",
         "-0.86819047",
         "0.2848049",
         "-2.0656323",
         "1.2826068",
         "-0.8574103",
         "-0.08016257",
         "0.23767081"
        ],
        [
         "study",
         "0.18440148",
         "0.68299687",
         "-1.0299617",
         "-0.14844184",
         "0.41441432",
         "0.5495441",
         "-0.51108915",
         "-0.7517161",
         "0.33979937",
         "-0.23508681"
        ],
        [
         "with",
         "-1.280277",
         "-0.73504305",
         "-0.014874104",
         "-0.35211697",
         "0.20723327",
         "-0.59994835",
         "0.7082836",
         "0.2918391",
         "0.0294809",
         "-1.0223614"
        ],
        [
         "process.",
         "-0.6149129",
         "1.4362887",
         "-1.4332945",
         "-0.1640454",
         "-0.5724048",
         "-0.32502407",
         "-1.2192385",
         "0.21428196",
         "0.4266996",
         "0.91711754"
        ],
        [
         "abstract",
         "-0.5295062",
         "-0.9172032",
         "0.47383988",
         "-2.6462042",
         "-1.8305402",
         "-2.1550932",
         "-1.0206305",
         "-0.06262846",
         "0.66273886",
         "-0.13219102"
        ],
        [
         "pattern",
         "1.3845148",
         "1.0984626",
         "1.4262547",
         "0.48959866",
         "-0.5080342",
         "1.6294554",
         "0.46569958",
         "0.7158829",
         "0.68689543",
         "0.24752757"
        ],
        [
         "create",
         "-0.34675694",
         "-0.8956374",
         "-0.030039214",
         "-0.5460537",
         "0.22371091",
         "-0.01524894",
         "-1.054611",
         "-0.35368732",
         "-0.6868414",
         "0.9013698"
        ],
        [
         "programs",
         "0.003689804",
         "-0.10865587",
         "0.32916257",
         "-0.68857193",
         "0.21094523",
         "0.6687578",
         "0.5345025",
         "-0.20617563",
         "-0.81729454",
         "-0.3052111"
        ],
        [
         "effect,",
         "1.017822",
         "2.0482244",
         "-3.0992877",
         "-0.8908004",
         "-1.1017929",
         "-1.9283756",
         "-0.53526986",
         "1.3588407",
         "0.35638192",
         "0.45668262"
        ],
        [
         "As",
         "-0.606002",
         "0.14109513",
         "0.010668021",
         "-0.49488035",
         "-0.69959307",
         "2.5055027",
         "-0.93696874",
         "-0.3800497",
         "-0.31591964",
         "-0.19984123"
        ],
        [
         "is",
         "-0.86426586",
         "1.421501",
         "1.0315058",
         "2.4015176",
         "0.5051159",
         "-0.83548516",
         "-0.36171892",
         "1.0722396",
         "1.1264186",
         "-2.2442837"
        ],
        [
         "We",
         "0.29674548",
         "0.70729357",
         "-0.20148748",
         "-0.23871945",
         "-1.774366",
         "1.3204739",
         "-0.2525243",
         "1.3114973",
         "0.09955559",
         "-0.6372385"
        ],
        [
         "process",
         "1.8901874",
         "-0.20634179",
         "-0.29263502",
         "-0.11403651",
         "-2.0580637",
         "0.8018501",
         "0.66089225",
         "2.2376032",
         "-1.3476926",
         "0.31129634"
        ],
        [
         "our",
         "-0.3584476",
         "-0.1118084",
         "0.51061344",
         "0.20185447",
         "1.1806716",
         "0.584008",
         "1.2384849",
         "-1.3815413",
         "0.051922493",
         "-1.5488482"
        ],
        [
         "that",
         "-0.88536036",
         "-0.31576806",
         "-1.7951655",
         "-1.4451506",
         "0.89032215",
         "-0.7904394",
         "-1.918109",
         "0.2285092",
         "-1.3937018",
         "0.0030237557"
        ],
        [
         "by",
         "-0.5749837",
         "-0.12609382",
         "-1.0262303",
         "1.0583546",
         "-1.9290751",
         "-1.0332847",
         "0.53070486",
         "-0.9444984",
         "-0.30786106",
         "-1.0431921"
        ],
        [
         "direct",
         "-1.3074228",
         "1.5932393",
         "-0.676628",
         "-0.76936424",
         "-0.5213144",
         "-0.3834864",
         "0.99100083",
         "0.2736736",
         "1.8603494",
         "-0.22084448"
        ],
        [
         "spirits",
         "0.9981955",
         "1.3968543",
         "1.1761827",
         "0.9796832",
         "0.93796235",
         "0.07049246",
         "-0.97893035",
         "0.5425143",
         "-0.4636371",
         "1.3198323"
        ],
        [
         "manipulate",
         "1.9236865",
         "-0.4064606",
         "1.4162931",
         "-1.1284199",
         "0.1720403",
         "-1.5056626",
         "-0.50514203",
         "0.83993316",
         "-1.5208864",
         "-1.0939838"
        ],
        [
         "called",
         "-0.883006",
         "1.2873507",
         "-0.50948334",
         "-1.2329826",
         "-2.1805997",
         "-1.5121607",
         "-0.33976611",
         "-2.8907518",
         "-0.33746284",
         "1.1194336"
        ],
        [
         "idea",
         "-0.3850373",
         "-1.1995246",
         "-2.7585528",
         "-0.3628895",
         "-0.064488076",
         "-0.57544744",
         "0.8030598",
         "0.7271965",
         "0.05959195",
         "-0.7896888"
        ],
        [
         "conjure",
         "-0.52588356",
         "0.1834905",
         "-1.2311792",
         "-0.40257564",
         "-0.32902363",
         "-2.1192904",
         "-2.055086",
         "-0.95003605",
         "0.17214797",
         "-1.1580911"
        ],
        [
         "inhabit",
         "0.8383711",
         "1.7145234",
         "2.0822935",
         "-0.005755924",
         "0.5976999",
         "0.099486575",
         "-1.4820775",
         "-0.81976956",
         "-1.2581314",
         "0.68042046"
        ],
        [
         "the",
         "-0.68403524",
         "-1.7228998",
         "-0.26161095",
         "-0.68280214",
         "2.5797951",
         "1.2470717",
         "1.6005976",
         "-0.92052406",
         "-0.95021915",
         "-0.64435565"
        ],
        [
         "a",
         "-1.6097014",
         "0.07935678",
         "0.20810072",
         "-0.23999353",
         "0.36038986",
         "0.3188327",
         "-0.522834",
         "1.3732486",
         "-0.24223123",
         "0.03539664"
        ],
        [
         "directed",
         "0.5798256",
         "-0.8902135",
         "-0.31029582",
         "-0.616904",
         "0.43937123",
         "-0.006255916",
         "-0.9422595",
         "0.18330246",
         "-0.94115996",
         "-0.51751447"
        ],
        [
         "data.",
         "-0.86906135",
         "0.15267284",
         "0.023992725",
         "1.1314589",
         "-0.577419",
         "-0.46085945",
         "-0.009954182",
         "-0.63589215",
         "1.8528286",
         "1.9809892"
        ],
        [
         "to",
         "1.0116262",
         "-0.8919117",
         "-0.023291776",
         "1.6316457",
         "0.10883836",
         "0.14017816",
         "2.5707498",
         "0.62378454",
         "-0.36095566",
         "-0.66185117"
        ],
        [
         "In",
         "-0.7542709",
         "1.1246834",
         "0.47519034",
         "-1.0770712",
         "-0.51888114",
         "0.22247948",
         "-0.72911626",
         "-0.044839766",
         "-0.50908065",
         "-0.57403356"
        ],
        [
         "beings",
         "1.8713712",
         "-0.89537746",
         "1.1528999",
         "-1.2084929",
         "0.58937293",
         "0.57583785",
         "-0.7782795",
         "0.53641057",
         "-2.0749214",
         "0.47318134"
        ],
        [
         "computers.",
         "2.185786",
         "-1.2282275",
         "-0.4844582",
         "0.08072448",
         "-0.08652089",
         "0.06609158",
         "0.8123704",
         "1.1841179",
         "2.6135712",
         "0.059164982"
        ],
        [
         "are",
         "-1.0866224",
         "-0.10987718",
         "-0.3970754",
         "0.67252475",
         "0.16234355",
         "-1.6617092",
         "1.0586076",
         "0.7726084",
         "-0.4210036",
         "0.683605"
        ],
        [
         "of",
         "0.072903134",
         "1.1181065",
         "-1.6350005",
         "-0.8519972",
         "-0.6791402",
         "0.19158356",
         "-0.51001567",
         "2.3712468",
         "1.0905192",
         "-2.6287045"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 49
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dim1</th>\n",
       "      <th>Dim2</th>\n",
       "      <th>Dim3</th>\n",
       "      <th>Dim4</th>\n",
       "      <th>Dim5</th>\n",
       "      <th>Dim6</th>\n",
       "      <th>Dim7</th>\n",
       "      <th>Dim8</th>\n",
       "      <th>Dim9</th>\n",
       "      <th>Dim10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>computational</th>\n",
       "      <td>-0.667542</td>\n",
       "      <td>0.334508</td>\n",
       "      <td>-1.247375</td>\n",
       "      <td>-0.562660</td>\n",
       "      <td>-1.771379</td>\n",
       "      <td>-0.754330</td>\n",
       "      <td>0.635134</td>\n",
       "      <td>-0.241553</td>\n",
       "      <td>0.438324</td>\n",
       "      <td>1.810085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processes</th>\n",
       "      <td>-0.314025</td>\n",
       "      <td>-0.459440</td>\n",
       "      <td>0.589650</td>\n",
       "      <td>1.720078</td>\n",
       "      <td>-0.568893</td>\n",
       "      <td>-0.850160</td>\n",
       "      <td>0.460905</td>\n",
       "      <td>-2.700313</td>\n",
       "      <td>-0.936856</td>\n",
       "      <td>-0.907490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spells.</th>\n",
       "      <td>-0.170851</td>\n",
       "      <td>1.582510</td>\n",
       "      <td>-1.186557</td>\n",
       "      <td>1.303331</td>\n",
       "      <td>-0.510969</td>\n",
       "      <td>2.334965</td>\n",
       "      <td>-1.935604</td>\n",
       "      <td>1.225858</td>\n",
       "      <td>0.773485</td>\n",
       "      <td>0.037681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>-1.207395</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.702124</td>\n",
       "      <td>1.028797</td>\n",
       "      <td>-0.751891</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>-1.573422</td>\n",
       "      <td>-1.539577</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>-0.595537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>1.993170</td>\n",
       "      <td>-1.123482</td>\n",
       "      <td>0.694861</td>\n",
       "      <td>-0.577210</td>\n",
       "      <td>-0.569877</td>\n",
       "      <td>0.536461</td>\n",
       "      <td>0.929991</td>\n",
       "      <td>0.488416</td>\n",
       "      <td>-0.283366</td>\n",
       "      <td>0.336540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.372892</td>\n",
       "      <td>-0.392172</td>\n",
       "      <td>-0.042960</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.149853</td>\n",
       "      <td>-1.874531</td>\n",
       "      <td>-0.283943</td>\n",
       "      <td>0.239770</td>\n",
       "      <td>0.677913</td>\n",
       "      <td>1.253537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processes.</th>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.298530</td>\n",
       "      <td>0.468822</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.580149</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>-1.116288</td>\n",
       "      <td>0.620169</td>\n",
       "      <td>1.067976</td>\n",
       "      <td>-1.225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rules</th>\n",
       "      <td>-0.870946</td>\n",
       "      <td>-0.930983</td>\n",
       "      <td>-1.657568</td>\n",
       "      <td>-0.188027</td>\n",
       "      <td>-0.204704</td>\n",
       "      <td>-0.159206</td>\n",
       "      <td>0.238914</td>\n",
       "      <td>0.168362</td>\n",
       "      <td>0.750724</td>\n",
       "      <td>-0.648405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolution</th>\n",
       "      <td>-0.307102</td>\n",
       "      <td>-0.053045</td>\n",
       "      <td>1.261929</td>\n",
       "      <td>-1.199492</td>\n",
       "      <td>0.879612</td>\n",
       "      <td>-1.045332</td>\n",
       "      <td>-0.249687</td>\n",
       "      <td>0.676510</td>\n",
       "      <td>-1.344324</td>\n",
       "      <td>-0.341031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computational</th>\n",
       "      <td>2.054966</td>\n",
       "      <td>0.927570</td>\n",
       "      <td>-0.867204</td>\n",
       "      <td>-1.501737</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>1.194267</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>-0.648118</td>\n",
       "      <td>-0.634796</td>\n",
       "      <td>0.635731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>0.676011</td>\n",
       "      <td>-0.415854</td>\n",
       "      <td>0.498860</td>\n",
       "      <td>-0.445853</td>\n",
       "      <td>-0.967790</td>\n",
       "      <td>-0.537403</td>\n",
       "      <td>0.732029</td>\n",
       "      <td>-1.168036</td>\n",
       "      <td>-1.859444</td>\n",
       "      <td>-2.067057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolve,</th>\n",
       "      <td>-0.102106</td>\n",
       "      <td>-0.185345</td>\n",
       "      <td>-1.155289</td>\n",
       "      <td>-1.433415</td>\n",
       "      <td>-0.419323</td>\n",
       "      <td>0.123055</td>\n",
       "      <td>0.061303</td>\n",
       "      <td>0.259210</td>\n",
       "      <td>0.434257</td>\n",
       "      <td>-1.394075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>things</th>\n",
       "      <td>-0.400260</td>\n",
       "      <td>0.418056</td>\n",
       "      <td>1.488245</td>\n",
       "      <td>0.687722</td>\n",
       "      <td>1.088237</td>\n",
       "      <td>-0.743504</td>\n",
       "      <td>1.492544</td>\n",
       "      <td>0.383096</td>\n",
       "      <td>0.300705</td>\n",
       "      <td>0.028636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>0.244516</td>\n",
       "      <td>1.192996</td>\n",
       "      <td>-0.152319</td>\n",
       "      <td>-0.608860</td>\n",
       "      <td>0.121005</td>\n",
       "      <td>1.867857</td>\n",
       "      <td>-0.292829</td>\n",
       "      <td>-0.974530</td>\n",
       "      <td>0.891450</td>\n",
       "      <td>-0.291301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program.</th>\n",
       "      <td>0.600287</td>\n",
       "      <td>-0.659261</td>\n",
       "      <td>-0.445282</td>\n",
       "      <td>-2.679033</td>\n",
       "      <td>-0.450815</td>\n",
       "      <td>-0.546575</td>\n",
       "      <td>-0.821789</td>\n",
       "      <td>0.058136</td>\n",
       "      <td>-1.092267</td>\n",
       "      <td>-1.165910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>0.983671</td>\n",
       "      <td>0.915729</td>\n",
       "      <td>-1.771034</td>\n",
       "      <td>-1.062415</td>\n",
       "      <td>0.273630</td>\n",
       "      <td>0.052560</td>\n",
       "      <td>0.766350</td>\n",
       "      <td>1.036082</td>\n",
       "      <td>0.205336</td>\n",
       "      <td>-0.257038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>0.152381</td>\n",
       "      <td>1.581300</td>\n",
       "      <td>-0.868794</td>\n",
       "      <td>-0.868190</td>\n",
       "      <td>0.284805</td>\n",
       "      <td>-2.065632</td>\n",
       "      <td>1.282607</td>\n",
       "      <td>-0.857410</td>\n",
       "      <td>-0.080163</td>\n",
       "      <td>0.237671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>0.184401</td>\n",
       "      <td>0.682997</td>\n",
       "      <td>-1.029962</td>\n",
       "      <td>-0.148442</td>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.549544</td>\n",
       "      <td>-0.511089</td>\n",
       "      <td>-0.751716</td>\n",
       "      <td>0.339799</td>\n",
       "      <td>-0.235087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>-1.280277</td>\n",
       "      <td>-0.735043</td>\n",
       "      <td>-0.014874</td>\n",
       "      <td>-0.352117</td>\n",
       "      <td>0.207233</td>\n",
       "      <td>-0.599948</td>\n",
       "      <td>0.708284</td>\n",
       "      <td>0.291839</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>-1.022361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process.</th>\n",
       "      <td>-0.614913</td>\n",
       "      <td>1.436289</td>\n",
       "      <td>-1.433295</td>\n",
       "      <td>-0.164045</td>\n",
       "      <td>-0.572405</td>\n",
       "      <td>-0.325024</td>\n",
       "      <td>-1.219239</td>\n",
       "      <td>0.214282</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.917118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>-0.529506</td>\n",
       "      <td>-0.917203</td>\n",
       "      <td>0.473840</td>\n",
       "      <td>-2.646204</td>\n",
       "      <td>-1.830540</td>\n",
       "      <td>-2.155093</td>\n",
       "      <td>-1.020630</td>\n",
       "      <td>-0.062628</td>\n",
       "      <td>0.662739</td>\n",
       "      <td>-0.132191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern</th>\n",
       "      <td>1.384515</td>\n",
       "      <td>1.098463</td>\n",
       "      <td>1.426255</td>\n",
       "      <td>0.489599</td>\n",
       "      <td>-0.508034</td>\n",
       "      <td>1.629455</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.715883</td>\n",
       "      <td>0.686895</td>\n",
       "      <td>0.247528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create</th>\n",
       "      <td>-0.346757</td>\n",
       "      <td>-0.895637</td>\n",
       "      <td>-0.030039</td>\n",
       "      <td>-0.546054</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>-0.015249</td>\n",
       "      <td>-1.054611</td>\n",
       "      <td>-0.353687</td>\n",
       "      <td>-0.686841</td>\n",
       "      <td>0.901370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>programs</th>\n",
       "      <td>0.003690</td>\n",
       "      <td>-0.108656</td>\n",
       "      <td>0.329163</td>\n",
       "      <td>-0.688572</td>\n",
       "      <td>0.210945</td>\n",
       "      <td>0.668758</td>\n",
       "      <td>0.534503</td>\n",
       "      <td>-0.206176</td>\n",
       "      <td>-0.817295</td>\n",
       "      <td>-0.305211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect,</th>\n",
       "      <td>1.017822</td>\n",
       "      <td>2.048224</td>\n",
       "      <td>-3.099288</td>\n",
       "      <td>-0.890800</td>\n",
       "      <td>-1.101793</td>\n",
       "      <td>-1.928376</td>\n",
       "      <td>-0.535270</td>\n",
       "      <td>1.358841</td>\n",
       "      <td>0.356382</td>\n",
       "      <td>0.456683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>As</th>\n",
       "      <td>-0.606002</td>\n",
       "      <td>0.141095</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>-0.494880</td>\n",
       "      <td>-0.699593</td>\n",
       "      <td>2.505503</td>\n",
       "      <td>-0.936969</td>\n",
       "      <td>-0.380050</td>\n",
       "      <td>-0.315920</td>\n",
       "      <td>-0.199841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.864266</td>\n",
       "      <td>1.421501</td>\n",
       "      <td>1.031506</td>\n",
       "      <td>2.401518</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>-0.835485</td>\n",
       "      <td>-0.361719</td>\n",
       "      <td>1.072240</td>\n",
       "      <td>1.126419</td>\n",
       "      <td>-2.244284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We</th>\n",
       "      <td>0.296745</td>\n",
       "      <td>0.707294</td>\n",
       "      <td>-0.201487</td>\n",
       "      <td>-0.238719</td>\n",
       "      <td>-1.774366</td>\n",
       "      <td>1.320474</td>\n",
       "      <td>-0.252524</td>\n",
       "      <td>1.311497</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>-0.637239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>1.890187</td>\n",
       "      <td>-0.206342</td>\n",
       "      <td>-0.292635</td>\n",
       "      <td>-0.114037</td>\n",
       "      <td>-2.058064</td>\n",
       "      <td>0.801850</td>\n",
       "      <td>0.660892</td>\n",
       "      <td>2.237603</td>\n",
       "      <td>-1.347693</td>\n",
       "      <td>0.311296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>-0.358448</td>\n",
       "      <td>-0.111808</td>\n",
       "      <td>0.510613</td>\n",
       "      <td>0.201854</td>\n",
       "      <td>1.180672</td>\n",
       "      <td>0.584008</td>\n",
       "      <td>1.238485</td>\n",
       "      <td>-1.381541</td>\n",
       "      <td>0.051922</td>\n",
       "      <td>-1.548848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.885360</td>\n",
       "      <td>-0.315768</td>\n",
       "      <td>-1.795166</td>\n",
       "      <td>-1.445151</td>\n",
       "      <td>0.890322</td>\n",
       "      <td>-0.790439</td>\n",
       "      <td>-1.918109</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>-1.393702</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>-0.574984</td>\n",
       "      <td>-0.126094</td>\n",
       "      <td>-1.026230</td>\n",
       "      <td>1.058355</td>\n",
       "      <td>-1.929075</td>\n",
       "      <td>-1.033285</td>\n",
       "      <td>0.530705</td>\n",
       "      <td>-0.944498</td>\n",
       "      <td>-0.307861</td>\n",
       "      <td>-1.043192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct</th>\n",
       "      <td>-1.307423</td>\n",
       "      <td>1.593239</td>\n",
       "      <td>-0.676628</td>\n",
       "      <td>-0.769364</td>\n",
       "      <td>-0.521314</td>\n",
       "      <td>-0.383486</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.273674</td>\n",
       "      <td>1.860349</td>\n",
       "      <td>-0.220844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirits</th>\n",
       "      <td>0.998196</td>\n",
       "      <td>1.396854</td>\n",
       "      <td>1.176183</td>\n",
       "      <td>0.979683</td>\n",
       "      <td>0.937962</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>-0.978930</td>\n",
       "      <td>0.542514</td>\n",
       "      <td>-0.463637</td>\n",
       "      <td>1.319832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manipulate</th>\n",
       "      <td>1.923687</td>\n",
       "      <td>-0.406461</td>\n",
       "      <td>1.416293</td>\n",
       "      <td>-1.128420</td>\n",
       "      <td>0.172040</td>\n",
       "      <td>-1.505663</td>\n",
       "      <td>-0.505142</td>\n",
       "      <td>0.839933</td>\n",
       "      <td>-1.520886</td>\n",
       "      <td>-1.093984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>-0.883006</td>\n",
       "      <td>1.287351</td>\n",
       "      <td>-0.509483</td>\n",
       "      <td>-1.232983</td>\n",
       "      <td>-2.180600</td>\n",
       "      <td>-1.512161</td>\n",
       "      <td>-0.339766</td>\n",
       "      <td>-2.890752</td>\n",
       "      <td>-0.337463</td>\n",
       "      <td>1.119434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idea</th>\n",
       "      <td>-0.385037</td>\n",
       "      <td>-1.199525</td>\n",
       "      <td>-2.758553</td>\n",
       "      <td>-0.362889</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>-0.575447</td>\n",
       "      <td>0.803060</td>\n",
       "      <td>0.727197</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>-0.789689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conjure</th>\n",
       "      <td>-0.525884</td>\n",
       "      <td>0.183490</td>\n",
       "      <td>-1.231179</td>\n",
       "      <td>-0.402576</td>\n",
       "      <td>-0.329024</td>\n",
       "      <td>-2.119290</td>\n",
       "      <td>-2.055086</td>\n",
       "      <td>-0.950036</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>-1.158091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inhabit</th>\n",
       "      <td>0.838371</td>\n",
       "      <td>1.714523</td>\n",
       "      <td>2.082294</td>\n",
       "      <td>-0.005756</td>\n",
       "      <td>0.597700</td>\n",
       "      <td>0.099487</td>\n",
       "      <td>-1.482077</td>\n",
       "      <td>-0.819770</td>\n",
       "      <td>-1.258131</td>\n",
       "      <td>0.680420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.684035</td>\n",
       "      <td>-1.722900</td>\n",
       "      <td>-0.261611</td>\n",
       "      <td>-0.682802</td>\n",
       "      <td>2.579795</td>\n",
       "      <td>1.247072</td>\n",
       "      <td>1.600598</td>\n",
       "      <td>-0.920524</td>\n",
       "      <td>-0.950219</td>\n",
       "      <td>-0.644356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-1.609701</td>\n",
       "      <td>0.079357</td>\n",
       "      <td>0.208101</td>\n",
       "      <td>-0.239994</td>\n",
       "      <td>0.360390</td>\n",
       "      <td>0.318833</td>\n",
       "      <td>-0.522834</td>\n",
       "      <td>1.373249</td>\n",
       "      <td>-0.242231</td>\n",
       "      <td>0.035397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>directed</th>\n",
       "      <td>0.579826</td>\n",
       "      <td>-0.890213</td>\n",
       "      <td>-0.310296</td>\n",
       "      <td>-0.616904</td>\n",
       "      <td>0.439371</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>-0.942259</td>\n",
       "      <td>0.183302</td>\n",
       "      <td>-0.941160</td>\n",
       "      <td>-0.517514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data.</th>\n",
       "      <td>-0.869061</td>\n",
       "      <td>0.152673</td>\n",
       "      <td>0.023993</td>\n",
       "      <td>1.131459</td>\n",
       "      <td>-0.577419</td>\n",
       "      <td>-0.460859</td>\n",
       "      <td>-0.009954</td>\n",
       "      <td>-0.635892</td>\n",
       "      <td>1.852829</td>\n",
       "      <td>1.980989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1.011626</td>\n",
       "      <td>-0.891912</td>\n",
       "      <td>-0.023292</td>\n",
       "      <td>1.631646</td>\n",
       "      <td>0.108838</td>\n",
       "      <td>0.140178</td>\n",
       "      <td>2.570750</td>\n",
       "      <td>0.623785</td>\n",
       "      <td>-0.360956</td>\n",
       "      <td>-0.661851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <td>-0.754271</td>\n",
       "      <td>1.124683</td>\n",
       "      <td>0.475190</td>\n",
       "      <td>-1.077071</td>\n",
       "      <td>-0.518881</td>\n",
       "      <td>0.222479</td>\n",
       "      <td>-0.729116</td>\n",
       "      <td>-0.044840</td>\n",
       "      <td>-0.509081</td>\n",
       "      <td>-0.574034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beings</th>\n",
       "      <td>1.871371</td>\n",
       "      <td>-0.895377</td>\n",
       "      <td>1.152900</td>\n",
       "      <td>-1.208493</td>\n",
       "      <td>0.589373</td>\n",
       "      <td>0.575838</td>\n",
       "      <td>-0.778279</td>\n",
       "      <td>0.536411</td>\n",
       "      <td>-2.074921</td>\n",
       "      <td>0.473181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers.</th>\n",
       "      <td>2.185786</td>\n",
       "      <td>-1.228227</td>\n",
       "      <td>-0.484458</td>\n",
       "      <td>0.080724</td>\n",
       "      <td>-0.086521</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.812370</td>\n",
       "      <td>1.184118</td>\n",
       "      <td>2.613571</td>\n",
       "      <td>0.059165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-1.086622</td>\n",
       "      <td>-0.109877</td>\n",
       "      <td>-0.397075</td>\n",
       "      <td>0.672525</td>\n",
       "      <td>0.162344</td>\n",
       "      <td>-1.661709</td>\n",
       "      <td>1.058608</td>\n",
       "      <td>0.772608</td>\n",
       "      <td>-0.421004</td>\n",
       "      <td>0.683605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.072903</td>\n",
       "      <td>1.118106</td>\n",
       "      <td>-1.635000</td>\n",
       "      <td>-0.851997</td>\n",
       "      <td>-0.679140</td>\n",
       "      <td>0.191584</td>\n",
       "      <td>-0.510016</td>\n",
       "      <td>2.371247</td>\n",
       "      <td>1.090519</td>\n",
       "      <td>-2.628705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dim1      Dim2      Dim3      Dim4      Dim5      Dim6  \\\n",
       "computational -0.667542  0.334508 -1.247375 -0.562660 -1.771379 -0.754330   \n",
       "processes     -0.314025 -0.459440  0.589650  1.720078 -0.568893 -0.850160   \n",
       "spells.       -0.170851  1.582510 -1.186557  1.303331 -0.510969  2.334965   \n",
       "about         -1.207395  0.341389  0.702124  1.028797 -0.751891  0.031643   \n",
       "The            1.993170 -1.123482  0.694861 -0.577210 -0.569877  0.536461   \n",
       "other          0.372892 -0.392172 -0.042960  0.914083  0.149853 -1.874531   \n",
       "processes.     0.169697  0.298530  0.468822  0.625850  0.580149  0.087816   \n",
       "rules         -0.870946 -0.930983 -1.657568 -0.188027 -0.204704 -0.159206   \n",
       "evolution     -0.307102 -0.053045  1.261929 -1.199492  0.879612 -1.045332   \n",
       "Computational  2.054966  0.927570 -0.867204 -1.501737 -0.687500  1.194267   \n",
       "they           0.676011 -0.415854  0.498860 -0.445853 -0.967790 -0.537403   \n",
       "evolve,       -0.102106 -0.185345 -1.155289 -1.433415 -0.419323  0.123055   \n",
       "things        -0.400260  0.418056  1.488245  0.687722  1.088237 -0.743504   \n",
       "we             0.244516  1.192996 -0.152319 -0.608860  0.121005  1.867857   \n",
       "program.       0.600287 -0.659261 -0.445282 -2.679033 -0.450815 -0.546575   \n",
       "People         0.983671  0.915729 -1.771034 -1.062415  0.273630  0.052560   \n",
       "computer       0.152381  1.581300 -0.868794 -0.868190  0.284805 -2.065632   \n",
       "study          0.184401  0.682997 -1.029962 -0.148442  0.414414  0.549544   \n",
       "with          -1.280277 -0.735043 -0.014874 -0.352117  0.207233 -0.599948   \n",
       "process.      -0.614913  1.436289 -1.433295 -0.164045 -0.572405 -0.325024   \n",
       "abstract      -0.529506 -0.917203  0.473840 -2.646204 -1.830540 -2.155093   \n",
       "pattern        1.384515  1.098463  1.426255  0.489599 -0.508034  1.629455   \n",
       "create        -0.346757 -0.895637 -0.030039 -0.546054  0.223711 -0.015249   \n",
       "programs       0.003690 -0.108656  0.329163 -0.688572  0.210945  0.668758   \n",
       "effect,        1.017822  2.048224 -3.099288 -0.890800 -1.101793 -1.928376   \n",
       "As            -0.606002  0.141095  0.010668 -0.494880 -0.699593  2.505503   \n",
       "is            -0.864266  1.421501  1.031506  2.401518  0.505116 -0.835485   \n",
       "We             0.296745  0.707294 -0.201487 -0.238719 -1.774366  1.320474   \n",
       "process        1.890187 -0.206342 -0.292635 -0.114037 -2.058064  0.801850   \n",
       "our           -0.358448 -0.111808  0.510613  0.201854  1.180672  0.584008   \n",
       "that          -0.885360 -0.315768 -1.795166 -1.445151  0.890322 -0.790439   \n",
       "by            -0.574984 -0.126094 -1.026230  1.058355 -1.929075 -1.033285   \n",
       "direct        -1.307423  1.593239 -0.676628 -0.769364 -0.521314 -0.383486   \n",
       "spirits        0.998196  1.396854  1.176183  0.979683  0.937962  0.070492   \n",
       "manipulate     1.923687 -0.406461  1.416293 -1.128420  0.172040 -1.505663   \n",
       "called        -0.883006  1.287351 -0.509483 -1.232983 -2.180600 -1.512161   \n",
       "idea          -0.385037 -1.199525 -2.758553 -0.362889 -0.064488 -0.575447   \n",
       "conjure       -0.525884  0.183490 -1.231179 -0.402576 -0.329024 -2.119290   \n",
       "inhabit        0.838371  1.714523  2.082294 -0.005756  0.597700  0.099487   \n",
       "the           -0.684035 -1.722900 -0.261611 -0.682802  2.579795  1.247072   \n",
       "a             -1.609701  0.079357  0.208101 -0.239994  0.360390  0.318833   \n",
       "directed       0.579826 -0.890213 -0.310296 -0.616904  0.439371 -0.006256   \n",
       "data.         -0.869061  0.152673  0.023993  1.131459 -0.577419 -0.460859   \n",
       "to             1.011626 -0.891912 -0.023292  1.631646  0.108838  0.140178   \n",
       "In            -0.754271  1.124683  0.475190 -1.077071 -0.518881  0.222479   \n",
       "beings         1.871371 -0.895377  1.152900 -1.208493  0.589373  0.575838   \n",
       "computers.     2.185786 -1.228227 -0.484458  0.080724 -0.086521  0.066092   \n",
       "are           -1.086622 -0.109877 -0.397075  0.672525  0.162344 -1.661709   \n",
       "of             0.072903  1.118106 -1.635000 -0.851997 -0.679140  0.191584   \n",
       "\n",
       "                   Dim7      Dim8      Dim9     Dim10  \n",
       "computational  0.635134 -0.241553  0.438324  1.810085  \n",
       "processes      0.460905 -2.700313 -0.936856 -0.907490  \n",
       "spells.       -1.935604  1.225858  0.773485  0.037681  \n",
       "about         -1.573422 -1.539577  0.963399 -0.595537  \n",
       "The            0.929991  0.488416 -0.283366  0.336540  \n",
       "other         -0.283943  0.239770  0.677913  1.253537  \n",
       "processes.    -1.116288  0.620169  1.067976 -1.225800  \n",
       "rules          0.238914  0.168362  0.750724 -0.648405  \n",
       "evolution     -0.249687  0.676510 -1.344324 -0.341031  \n",
       "Computational  0.036527 -0.648118 -0.634796  0.635731  \n",
       "they           0.732029 -1.168036 -1.859444 -2.067057  \n",
       "evolve,        0.061303  0.259210  0.434257 -1.394075  \n",
       "things         1.492544  0.383096  0.300705  0.028636  \n",
       "we            -0.292829 -0.974530  0.891450 -0.291301  \n",
       "program.      -0.821789  0.058136 -1.092267 -1.165910  \n",
       "People         0.766350  1.036082  0.205336 -0.257038  \n",
       "computer       1.282607 -0.857410 -0.080163  0.237671  \n",
       "study         -0.511089 -0.751716  0.339799 -0.235087  \n",
       "with           0.708284  0.291839  0.029481 -1.022361  \n",
       "process.      -1.219239  0.214282  0.426700  0.917118  \n",
       "abstract      -1.020630 -0.062628  0.662739 -0.132191  \n",
       "pattern        0.465700  0.715883  0.686895  0.247528  \n",
       "create        -1.054611 -0.353687 -0.686841  0.901370  \n",
       "programs       0.534503 -0.206176 -0.817295 -0.305211  \n",
       "effect,       -0.535270  1.358841  0.356382  0.456683  \n",
       "As            -0.936969 -0.380050 -0.315920 -0.199841  \n",
       "is            -0.361719  1.072240  1.126419 -2.244284  \n",
       "We            -0.252524  1.311497  0.099556 -0.637239  \n",
       "process        0.660892  2.237603 -1.347693  0.311296  \n",
       "our            1.238485 -1.381541  0.051922 -1.548848  \n",
       "that          -1.918109  0.228509 -1.393702  0.003024  \n",
       "by             0.530705 -0.944498 -0.307861 -1.043192  \n",
       "direct         0.991001  0.273674  1.860349 -0.220844  \n",
       "spirits       -0.978930  0.542514 -0.463637  1.319832  \n",
       "manipulate    -0.505142  0.839933 -1.520886 -1.093984  \n",
       "called        -0.339766 -2.890752 -0.337463  1.119434  \n",
       "idea           0.803060  0.727197  0.059592 -0.789689  \n",
       "conjure       -2.055086 -0.950036  0.172148 -1.158091  \n",
       "inhabit       -1.482077 -0.819770 -1.258131  0.680420  \n",
       "the            1.600598 -0.920524 -0.950219 -0.644356  \n",
       "a             -0.522834  1.373249 -0.242231  0.035397  \n",
       "directed      -0.942259  0.183302 -0.941160 -0.517514  \n",
       "data.         -0.009954 -0.635892  1.852829  1.980989  \n",
       "to             2.570750  0.623785 -0.360956 -0.661851  \n",
       "In            -0.729116 -0.044840 -0.509081 -0.574034  \n",
       "beings        -0.778279  0.536411 -2.074921  0.473181  \n",
       "computers.     0.812370  1.184118  2.613571  0.059165  \n",
       "are            1.058608  0.772608 -0.421004  0.683605  \n",
       "of            -0.510016  2.371247  1.090519 -2.628705  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import pandas as pd\n",
    "column_map = {i: f\"Dim{i+1}\" for i in range(EMBEDDING_DIM)}\n",
    "bag_of_words_df = pd.DataFrame()\n",
    "\n",
    "print(\"Final word embeddings for:\")\n",
    "for word in word_to_ix:\n",
    "    bag_of_words_df[word] = [i for i in np.array(model.embeddings.weight[word_to_ix[word]].detach())]\n",
    "\n",
    "bag_of_words_df = bag_of_words_df.T.rename(columns=column_map)\n",
    "\n",
    "bag_of_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96741e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "from gensim.models import KeyedVectors\n",
    "import argparse\n",
    "\n",
    "def reduce_dimensions(embeddings, method, dims):\n",
    "    \"\"\"\n",
    "    Reduce the dimensions of embeddings to 2D or 3D.\n",
    "\n",
    "    Parameters:\n",
    "    embeddings (array): High-dimensional embeddings.\n",
    "    method (str): Dimensionality reduction method ('pca', 'tsne', or 'umap').\n",
    "    dims (int): Number of dimensions to reduce embeddings to. \n",
    "    \"\"\"\n",
    "    n_samples = embeddings.shape[0]\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=dims)\n",
    "    elif method == 'tsne':\n",
    "        perplexity = min(30, max(n_samples // 3, 5))  # Adjust perplexity for small datasets\n",
    "        reducer = TSNE(n_components=dims, perplexity=perplexity, random_state=0)\n",
    "    elif method == 'umap':\n",
    "        reducer = umap.UMAP(n_components=dims)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method: choose 'pca', 'tsne', or 'umap'\")\n",
    "\n",
    "    return reducer.fit_transform(embeddings)\n",
    "\n",
    "def plot_embeddings(embeddings, words, n_clusters):\n",
    "    \"\"\"\n",
    "    Plot of the 2D embeddings using Plotly.\n",
    "    \"\"\"\n",
    "    # Perform clustering on the reduced embeddings\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Create a DataFrame for the embeddings, words, and clusters\n",
    "    df = pd.DataFrame(embeddings, columns=['x', 'y', 'z'])\n",
    "    df['word'] = words\n",
    "    df['cluster'] = cluster_labels\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', hover_name='word', color='cluster',\n",
    "                     title=\"Word Embeddings\", template='plotly', width=800, height=800)\n",
    "\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    \n",
    "    # Add text labels\n",
    "    for i, row in df.iterrows():\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[row['x']], y=[row['y']], z=[row['z']], \n",
    "                mode='text', text=[row['word']],\n",
    "                textposition='middle center',\n",
    "                showlegend=False\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Update traces and layout for better readability\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "    fig.update_layout(hovermode='closest', showlegend=True)\n",
    "    fig.update_layout(scene=dict(xaxis_showgrid=False, yaxis_showgrid=False, zaxis_showgrid=False))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bf20865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<br>z=%{z}<br>cluster=%{marker.color}<extra></extra>",
         "hovertext": [
          "computational",
          "processes",
          "spells.",
          "about",
          "The",
          "other",
          "processes.",
          "rules",
          "evolution",
          "Computational",
          "they",
          "evolve,",
          "things",
          "we",
          "program.",
          "People",
          "computer",
          "study",
          "with",
          "process.",
          "abstract",
          "pattern",
          "create",
          "programs",
          "effect,",
          "As",
          "is",
          "We",
          "process",
          "our",
          "that",
          "by",
          "direct",
          "spirits",
          "manipulate",
          "called",
          "idea",
          "conjure",
          "inhabit",
          "the",
          "a",
          "directed",
          "data.",
          "to",
          "In",
          "beings",
          "computers.",
          "are",
          "of"
         ],
         "legendgroup": "",
         "marker": {
          "color": [
           7,
           6,
           9,
           0,
           4,
           2,
           0,
           5,
           8,
           9,
           6,
           5,
           2,
           9,
           3,
           5,
           7,
           0,
           6,
           7,
           3,
           1,
           3,
           8,
           7,
           9,
           0,
           1,
           1,
           6,
           3,
           2,
           7,
           8,
           8,
           7,
           5,
           3,
           8,
           6,
           0,
           8,
           2,
           6,
           0,
           8,
           4,
           2,
           5
          ],
          "coloraxis": "coloraxis",
          "opacity": 0.7,
          "size": 6,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "scene": "scene",
         "showlegend": false,
         "type": "scatter3d",
         "x": [
          5.640820026397705,
          6.873641490936279,
          6.75775671005249,
          6.760962009429932,
          7.3068742752075195,
          6.081915855407715,
          7.070167541503906,
          5.929832935333252,
          7.973847389221191,
          6.429295063018799,
          7.516904354095459,
          6.0122246742248535,
          6.358222007751465,
          6.823696136474609,
          8.218856811523438,
          5.615318775177002,
          5.413079261779785,
          6.404467582702637,
          6.334869861602783,
          5.812312126159668,
          7.945899486541748,
          7.335629463195801,
          7.5516510009765625,
          7.372311115264893,
          5.508200168609619,
          7.076572418212891,
          6.816483974456787,
          6.8544087409973145,
          7.1401262283325195,
          6.888993740081787,
          8.09941577911377,
          6.326658248901367,
          5.5127363204956055,
          7.826056957244873,
          8.360278129577637,
          5.838260173797607,
          5.7484002113342285,
          7.87772274017334,
          8.063100814819336,
          7.010091781616211,
          7.059595584869385,
          8.151163101196289,
          5.965545654296875,
          6.711235523223877,
          7.037975311279297,
          8.334443092346191,
          6.655569076538086,
          5.899735927581787,
          5.912856578826904
         ],
         "y": [
          -0.2355567067861557,
          -1.0180027484893799,
          -2.2812609672546387,
          -0.666302502155304,
          -2.421395778656006,
          -0.13731412589550018,
          -0.9127953052520752,
          -1.3811513185501099,
          -1.3506406545639038,
          -1.6035782098770142,
          -1.5091238021850586,
          -1.7134183645248413,
          -0.7428829073905945,
          -1.6033488512039185,
          -0.9028614163398743,
          -1.7255146503448486,
          -0.5427281260490417,
          -0.9911479353904724,
          -1.3553252220153809,
          -0.7151086926460266,
          -0.5085582137107849,
          -2.2542123794555664,
          -0.7644089460372925,
          -1.6468276977539062,
          -1.1816461086273193,
          -1.9215809106826782,
          -0.48944976925849915,
          -2.491872787475586,
          -2.6359822750091553,
          -1.1966052055358887,
          -0.5653218626976013,
          -0.9987056255340576,
          -0.8865494728088379,
          -1.5002069473266602,
          -1.44950532913208,
          -0.20841257274150848,
          -1.757974624633789,
          -0.2113002985715866,
          -1.650644063949585,
          -1.5166513919830322,
          -1.0306771993637085,
          -1.1144030094146729,
          0.014269976876676083,
          -1.905367136001587,
          -1.3305085897445679,
          -1.743065595626831,
          -2.3397843837738037,
          -0.6364254355430603,
          -1.8358590602874756
         ],
         "z": [
          7.0215582847595215,
          6.323808193206787,
          8.118943214416504,
          7.860780239105225,
          6.743775367736816,
          6.5126872062683105,
          8.044700622558594,
          6.8177361488342285,
          6.779168605804443,
          8.302179336547852,
          6.25469970703125,
          7.28025484085083,
          5.8551201820373535,
          8.369888305664062,
          6.528746128082275,
          7.7282938957214355,
          6.859715938568115,
          8.112025260925293,
          6.072630882263184,
          7.801126956939697,
          6.460711479187012,
          7.729096412658691,
          7.146387577056885,
          6.762099742889404,
          7.812606334686279,
          8.31080150604248,
          7.50350284576416,
          7.807980060577393,
          7.238620758056641,
          5.801064491271973,
          7.032156944274902,
          6.550390720367432,
          7.30647611618042,
          7.632747173309326,
          6.438283920288086,
          7.356530666351318,
          6.846323490142822,
          7.236782550811768,
          7.302910804748535,
          5.670569896697998,
          7.069671154022217,
          7.042337894439697,
          6.923745632171631,
          6.029226779937744,
          7.451163291931152,
          6.673791408538818,
          6.762291431427002,
          6.1493239402771,
          7.565591335296631
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "computational"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.640820026397705
         ],
         "y": [
          -0.2355567067861557
         ],
         "z": [
          7.0215582847595215
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "processes"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.873641490936279
         ],
         "y": [
          -1.0180027484893799
         ],
         "z": [
          6.323808193206787
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "spells."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.75775671005249
         ],
         "y": [
          -2.2812609672546387
         ],
         "z": [
          8.118943214416504
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "about"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.760962009429932
         ],
         "y": [
          -0.666302502155304
         ],
         "z": [
          7.860780239105225
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "The"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.3068742752075195
         ],
         "y": [
          -2.421395778656006
         ],
         "z": [
          6.743775367736816
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "other"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.081915855407715
         ],
         "y": [
          -0.13731412589550018
         ],
         "z": [
          6.5126872062683105
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "processes."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.070167541503906
         ],
         "y": [
          -0.9127953052520752
         ],
         "z": [
          8.044700622558594
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "rules"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.929832935333252
         ],
         "y": [
          -1.3811513185501099
         ],
         "z": [
          6.8177361488342285
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "evolution"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.973847389221191
         ],
         "y": [
          -1.3506406545639038
         ],
         "z": [
          6.779168605804443
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "Computational"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.429295063018799
         ],
         "y": [
          -1.6035782098770142
         ],
         "z": [
          8.302179336547852
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "they"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.516904354095459
         ],
         "y": [
          -1.5091238021850586
         ],
         "z": [
          6.25469970703125
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "evolve,"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.0122246742248535
         ],
         "y": [
          -1.7134183645248413
         ],
         "z": [
          7.28025484085083
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "things"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.358222007751465
         ],
         "y": [
          -0.7428829073905945
         ],
         "z": [
          5.8551201820373535
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "we"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.823696136474609
         ],
         "y": [
          -1.6033488512039185
         ],
         "z": [
          8.369888305664062
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "program."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.218856811523438
         ],
         "y": [
          -0.9028614163398743
         ],
         "z": [
          6.528746128082275
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "People"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.615318775177002
         ],
         "y": [
          -1.7255146503448486
         ],
         "z": [
          7.7282938957214355
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "computer"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.413079261779785
         ],
         "y": [
          -0.5427281260490417
         ],
         "z": [
          6.859715938568115
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "study"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.404467582702637
         ],
         "y": [
          -0.9911479353904724
         ],
         "z": [
          8.112025260925293
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "with"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.334869861602783
         ],
         "y": [
          -1.3553252220153809
         ],
         "z": [
          6.072630882263184
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "process."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.812312126159668
         ],
         "y": [
          -0.7151086926460266
         ],
         "z": [
          7.801126956939697
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "abstract"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.945899486541748
         ],
         "y": [
          -0.5085582137107849
         ],
         "z": [
          6.460711479187012
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "pattern"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.335629463195801
         ],
         "y": [
          -2.2542123794555664
         ],
         "z": [
          7.729096412658691
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "create"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.5516510009765625
         ],
         "y": [
          -0.7644089460372925
         ],
         "z": [
          7.146387577056885
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "programs"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.372311115264893
         ],
         "y": [
          -1.6468276977539062
         ],
         "z": [
          6.762099742889404
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "effect,"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.508200168609619
         ],
         "y": [
          -1.1816461086273193
         ],
         "z": [
          7.812606334686279
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "As"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.076572418212891
         ],
         "y": [
          -1.9215809106826782
         ],
         "z": [
          8.31080150604248
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "is"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.816483974456787
         ],
         "y": [
          -0.48944976925849915
         ],
         "z": [
          7.50350284576416
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "We"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.8544087409973145
         ],
         "y": [
          -2.491872787475586
         ],
         "z": [
          7.807980060577393
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "process"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.1401262283325195
         ],
         "y": [
          -2.6359822750091553
         ],
         "z": [
          7.238620758056641
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "our"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.888993740081787
         ],
         "y": [
          -1.1966052055358887
         ],
         "z": [
          5.801064491271973
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "that"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.09941577911377
         ],
         "y": [
          -0.5653218626976013
         ],
         "z": [
          7.032156944274902
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "by"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.326658248901367
         ],
         "y": [
          -0.9987056255340576
         ],
         "z": [
          6.550390720367432
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "direct"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.5127363204956055
         ],
         "y": [
          -0.8865494728088379
         ],
         "z": [
          7.30647611618042
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "spirits"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.826056957244873
         ],
         "y": [
          -1.5002069473266602
         ],
         "z": [
          7.632747173309326
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "manipulate"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.360278129577637
         ],
         "y": [
          -1.44950532913208
         ],
         "z": [
          6.438283920288086
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "called"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.838260173797607
         ],
         "y": [
          -0.20841257274150848
         ],
         "z": [
          7.356530666351318
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "idea"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.7484002113342285
         ],
         "y": [
          -1.757974624633789
         ],
         "z": [
          6.846323490142822
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "conjure"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.87772274017334
         ],
         "y": [
          -0.2113002985715866
         ],
         "z": [
          7.236782550811768
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "inhabit"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.063100814819336
         ],
         "y": [
          -1.650644063949585
         ],
         "z": [
          7.302910804748535
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "the"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.010091781616211
         ],
         "y": [
          -1.5166513919830322
         ],
         "z": [
          5.670569896697998
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "a"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.059595584869385
         ],
         "y": [
          -1.0306771993637085
         ],
         "z": [
          7.069671154022217
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "directed"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.151163101196289
         ],
         "y": [
          -1.1144030094146729
         ],
         "z": [
          7.042337894439697
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "data."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.965545654296875
         ],
         "y": [
          0.014269976876676083
         ],
         "z": [
          6.923745632171631
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "to"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.711235523223877
         ],
         "y": [
          -1.905367136001587
         ],
         "z": [
          6.029226779937744
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "In"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          7.037975311279297
         ],
         "y": [
          -1.3305085897445679
         ],
         "z": [
          7.451163291931152
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "beings"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          8.334443092346191
         ],
         "y": [
          -1.743065595626831
         ],
         "z": [
          6.673791408538818
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "computers."
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          6.655569076538086
         ],
         "y": [
          -2.3397843837738037
         ],
         "z": [
          6.762291431427002
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "are"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.899735927581787
         ],
         "y": [
          -0.6364254355430603
         ],
         "z": [
          6.1493239402771
         ]
        },
        {
         "marker": {
          "opacity": 0.7,
          "size": 6
         },
         "mode": "text",
         "showlegend": false,
         "text": [
          "of"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          5.912856578826904
         ],
         "y": [
          -1.8358590602874756
         ],
         "z": [
          7.565591335296631
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "cluster"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ],
         "showscale": false
        },
        "height": 800,
        "hovermode": "closest",
        "legend": {
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "showgrid": false,
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "showgrid": false,
          "title": {
           "text": "y"
          }
         },
         "zaxis": {
          "showgrid": false,
          "title": {
           "text": "z"
          }
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Word Embeddings"
        },
        "width": 800
       }
      },
      "text/html": [
       "<div>                            <div id=\"43a547ef-8f25-4298-be98-2458f052e6ae\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"43a547ef-8f25-4298-be98-2458f052e6ae\")) {                    Plotly.newPlot(                        \"43a547ef-8f25-4298-be98-2458f052e6ae\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003ecluster=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"computational\",\"processes\",\"spells.\",\"about\",\"The\",\"other\",\"processes.\",\"rules\",\"evolution\",\"Computational\",\"they\",\"evolve,\",\"things\",\"we\",\"program.\",\"People\",\"computer\",\"study\",\"with\",\"process.\",\"abstract\",\"pattern\",\"create\",\"programs\",\"effect,\",\"As\",\"is\",\"We\",\"process\",\"our\",\"that\",\"by\",\"direct\",\"spirits\",\"manipulate\",\"called\",\"idea\",\"conjure\",\"inhabit\",\"the\",\"a\",\"directed\",\"data.\",\"to\",\"In\",\"beings\",\"computers.\",\"are\",\"of\"],\"legendgroup\":\"\",\"marker\":{\"color\":[7,6,9,0,4,2,0,5,8,9,6,5,2,9,3,5,7,0,6,7,3,1,3,8,7,9,0,1,1,6,3,2,7,8,8,7,5,3,8,6,0,8,2,6,0,8,4,2,5],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\",\"opacity\":0.7,\"size\":6},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"x\":[5.640820026397705,6.873641490936279,6.75775671005249,6.760962009429932,7.3068742752075195,6.081915855407715,7.070167541503906,5.929832935333252,7.973847389221191,6.429295063018799,7.516904354095459,6.0122246742248535,6.358222007751465,6.823696136474609,8.218856811523438,5.615318775177002,5.413079261779785,6.404467582702637,6.334869861602783,5.812312126159668,7.945899486541748,7.335629463195801,7.5516510009765625,7.372311115264893,5.508200168609619,7.076572418212891,6.816483974456787,6.8544087409973145,7.1401262283325195,6.888993740081787,8.09941577911377,6.326658248901367,5.5127363204956055,7.826056957244873,8.360278129577637,5.838260173797607,5.7484002113342285,7.87772274017334,8.063100814819336,7.010091781616211,7.059595584869385,8.151163101196289,5.965545654296875,6.711235523223877,7.037975311279297,8.334443092346191,6.655569076538086,5.899735927581787,5.912856578826904],\"y\":[-0.2355567067861557,-1.0180027484893799,-2.2812609672546387,-0.666302502155304,-2.421395778656006,-0.13731412589550018,-0.9127953052520752,-1.3811513185501099,-1.3506406545639038,-1.6035782098770142,-1.5091238021850586,-1.7134183645248413,-0.7428829073905945,-1.6033488512039185,-0.9028614163398743,-1.7255146503448486,-0.5427281260490417,-0.9911479353904724,-1.3553252220153809,-0.7151086926460266,-0.5085582137107849,-2.2542123794555664,-0.7644089460372925,-1.6468276977539062,-1.1816461086273193,-1.9215809106826782,-0.48944976925849915,-2.491872787475586,-2.6359822750091553,-1.1966052055358887,-0.5653218626976013,-0.9987056255340576,-0.8865494728088379,-1.5002069473266602,-1.44950532913208,-0.20841257274150848,-1.757974624633789,-0.2113002985715866,-1.650644063949585,-1.5166513919830322,-1.0306771993637085,-1.1144030094146729,0.014269976876676083,-1.905367136001587,-1.3305085897445679,-1.743065595626831,-2.3397843837738037,-0.6364254355430603,-1.8358590602874756],\"z\":[7.0215582847595215,6.323808193206787,8.118943214416504,7.860780239105225,6.743775367736816,6.5126872062683105,8.044700622558594,6.8177361488342285,6.779168605804443,8.302179336547852,6.25469970703125,7.28025484085083,5.8551201820373535,8.369888305664062,6.528746128082275,7.7282938957214355,6.859715938568115,8.112025260925293,6.072630882263184,7.801126956939697,6.460711479187012,7.729096412658691,7.146387577056885,6.762099742889404,7.812606334686279,8.31080150604248,7.50350284576416,7.807980060577393,7.238620758056641,5.801064491271973,7.032156944274902,6.550390720367432,7.30647611618042,7.632747173309326,6.438283920288086,7.356530666351318,6.846323490142822,7.236782550811768,7.302910804748535,5.670569896697998,7.069671154022217,7.042337894439697,6.923745632171631,6.029226779937744,7.451163291931152,6.673791408538818,6.762291431427002,6.1493239402771,7.565591335296631],\"type\":\"scatter3d\"},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"computational\"],\"textposition\":\"middle center\",\"x\":[5.640820026397705],\"y\":[-0.2355567067861557],\"z\":[7.0215582847595215],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"processes\"],\"textposition\":\"middle center\",\"x\":[6.873641490936279],\"y\":[-1.0180027484893799],\"z\":[6.323808193206787],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"spells.\"],\"textposition\":\"middle center\",\"x\":[6.75775671005249],\"y\":[-2.2812609672546387],\"z\":[8.118943214416504],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"about\"],\"textposition\":\"middle center\",\"x\":[6.760962009429932],\"y\":[-0.666302502155304],\"z\":[7.860780239105225],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"The\"],\"textposition\":\"middle center\",\"x\":[7.3068742752075195],\"y\":[-2.421395778656006],\"z\":[6.743775367736816],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"other\"],\"textposition\":\"middle center\",\"x\":[6.081915855407715],\"y\":[-0.13731412589550018],\"z\":[6.5126872062683105],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"processes.\"],\"textposition\":\"middle center\",\"x\":[7.070167541503906],\"y\":[-0.9127953052520752],\"z\":[8.044700622558594],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"rules\"],\"textposition\":\"middle center\",\"x\":[5.929832935333252],\"y\":[-1.3811513185501099],\"z\":[6.8177361488342285],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"evolution\"],\"textposition\":\"middle center\",\"x\":[7.973847389221191],\"y\":[-1.3506406545639038],\"z\":[6.779168605804443],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"Computational\"],\"textposition\":\"middle center\",\"x\":[6.429295063018799],\"y\":[-1.6035782098770142],\"z\":[8.302179336547852],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"they\"],\"textposition\":\"middle center\",\"x\":[7.516904354095459],\"y\":[-1.5091238021850586],\"z\":[6.25469970703125],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"evolve,\"],\"textposition\":\"middle center\",\"x\":[6.0122246742248535],\"y\":[-1.7134183645248413],\"z\":[7.28025484085083],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"things\"],\"textposition\":\"middle center\",\"x\":[6.358222007751465],\"y\":[-0.7428829073905945],\"z\":[5.8551201820373535],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"we\"],\"textposition\":\"middle center\",\"x\":[6.823696136474609],\"y\":[-1.6033488512039185],\"z\":[8.369888305664062],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"program.\"],\"textposition\":\"middle center\",\"x\":[8.218856811523438],\"y\":[-0.9028614163398743],\"z\":[6.528746128082275],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"People\"],\"textposition\":\"middle center\",\"x\":[5.615318775177002],\"y\":[-1.7255146503448486],\"z\":[7.7282938957214355],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"computer\"],\"textposition\":\"middle center\",\"x\":[5.413079261779785],\"y\":[-0.5427281260490417],\"z\":[6.859715938568115],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"study\"],\"textposition\":\"middle center\",\"x\":[6.404467582702637],\"y\":[-0.9911479353904724],\"z\":[8.112025260925293],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"with\"],\"textposition\":\"middle center\",\"x\":[6.334869861602783],\"y\":[-1.3553252220153809],\"z\":[6.072630882263184],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"process.\"],\"textposition\":\"middle center\",\"x\":[5.812312126159668],\"y\":[-0.7151086926460266],\"z\":[7.801126956939697],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"abstract\"],\"textposition\":\"middle center\",\"x\":[7.945899486541748],\"y\":[-0.5085582137107849],\"z\":[6.460711479187012],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"pattern\"],\"textposition\":\"middle center\",\"x\":[7.335629463195801],\"y\":[-2.2542123794555664],\"z\":[7.729096412658691],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"create\"],\"textposition\":\"middle center\",\"x\":[7.5516510009765625],\"y\":[-0.7644089460372925],\"z\":[7.146387577056885],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"programs\"],\"textposition\":\"middle center\",\"x\":[7.372311115264893],\"y\":[-1.6468276977539062],\"z\":[6.762099742889404],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"effect,\"],\"textposition\":\"middle center\",\"x\":[5.508200168609619],\"y\":[-1.1816461086273193],\"z\":[7.812606334686279],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"As\"],\"textposition\":\"middle center\",\"x\":[7.076572418212891],\"y\":[-1.9215809106826782],\"z\":[8.31080150604248],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"is\"],\"textposition\":\"middle center\",\"x\":[6.816483974456787],\"y\":[-0.48944976925849915],\"z\":[7.50350284576416],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"We\"],\"textposition\":\"middle center\",\"x\":[6.8544087409973145],\"y\":[-2.491872787475586],\"z\":[7.807980060577393],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"process\"],\"textposition\":\"middle center\",\"x\":[7.1401262283325195],\"y\":[-2.6359822750091553],\"z\":[7.238620758056641],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"our\"],\"textposition\":\"middle center\",\"x\":[6.888993740081787],\"y\":[-1.1966052055358887],\"z\":[5.801064491271973],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"that\"],\"textposition\":\"middle center\",\"x\":[8.09941577911377],\"y\":[-0.5653218626976013],\"z\":[7.032156944274902],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"by\"],\"textposition\":\"middle center\",\"x\":[6.326658248901367],\"y\":[-0.9987056255340576],\"z\":[6.550390720367432],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"direct\"],\"textposition\":\"middle center\",\"x\":[5.5127363204956055],\"y\":[-0.8865494728088379],\"z\":[7.30647611618042],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"spirits\"],\"textposition\":\"middle center\",\"x\":[7.826056957244873],\"y\":[-1.5002069473266602],\"z\":[7.632747173309326],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"manipulate\"],\"textposition\":\"middle center\",\"x\":[8.360278129577637],\"y\":[-1.44950532913208],\"z\":[6.438283920288086],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"called\"],\"textposition\":\"middle center\",\"x\":[5.838260173797607],\"y\":[-0.20841257274150848],\"z\":[7.356530666351318],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"idea\"],\"textposition\":\"middle center\",\"x\":[5.7484002113342285],\"y\":[-1.757974624633789],\"z\":[6.846323490142822],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"conjure\"],\"textposition\":\"middle center\",\"x\":[7.87772274017334],\"y\":[-0.2113002985715866],\"z\":[7.236782550811768],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"inhabit\"],\"textposition\":\"middle center\",\"x\":[8.063100814819336],\"y\":[-1.650644063949585],\"z\":[7.302910804748535],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"the\"],\"textposition\":\"middle center\",\"x\":[7.010091781616211],\"y\":[-1.5166513919830322],\"z\":[5.670569896697998],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"a\"],\"textposition\":\"middle center\",\"x\":[7.059595584869385],\"y\":[-1.0306771993637085],\"z\":[7.069671154022217],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"directed\"],\"textposition\":\"middle center\",\"x\":[8.151163101196289],\"y\":[-1.1144030094146729],\"z\":[7.042337894439697],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"data.\"],\"textposition\":\"middle center\",\"x\":[5.965545654296875],\"y\":[0.014269976876676083],\"z\":[6.923745632171631],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"to\"],\"textposition\":\"middle center\",\"x\":[6.711235523223877],\"y\":[-1.905367136001587],\"z\":[6.029226779937744],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"In\"],\"textposition\":\"middle center\",\"x\":[7.037975311279297],\"y\":[-1.3305085897445679],\"z\":[7.451163291931152],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"beings\"],\"textposition\":\"middle center\",\"x\":[8.334443092346191],\"y\":[-1.743065595626831],\"z\":[6.673791408538818],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"computers.\"],\"textposition\":\"middle center\",\"x\":[6.655569076538086],\"y\":[-2.3397843837738037],\"z\":[6.762291431427002],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"are\"],\"textposition\":\"middle center\",\"x\":[5.899735927581787],\"y\":[-0.6364254355430603],\"z\":[6.1493239402771],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}},{\"mode\":\"text\",\"showlegend\":false,\"text\":[\"of\"],\"textposition\":\"middle center\",\"x\":[5.912856578826904],\"y\":[-1.8358590602874756],\"z\":[7.565591335296631],\"type\":\"scatter3d\",\"marker\":{\"opacity\":0.7,\"size\":6}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"},\"showgrid\":false},\"yaxis\":{\"title\":{\"text\":\"y\"},\"showgrid\":false},\"zaxis\":{\"title\":{\"text\":\"z\"},\"showgrid\":false}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"cluster\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"showscale\":false},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Word Embeddings\"},\"height\":800,\"width\":800,\"hovermode\":\"closest\",\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('43a547ef-8f25-4298-be98-2458f052e6ae');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_final_embeddings = np.array([np.array(model.embeddings.weight[word_to_ix[i]].detach()) for i in vocab])\n",
    "embeddings_d = reduce_dimensions(all_final_embeddings, 'umap', 3)\n",
    "plot_embeddings(embeddings_d, list(vocab), n_clusters=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
